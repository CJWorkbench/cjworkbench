# Bring up all the pieces necessary to run the workbench
# Data persists in Docker volumes and in local dir

# This file passes through all necessary env variables to requisite
# Docker containers and makes them available when running commands via
# `docker exec`.

version: '3.4'

services:
  database:
    image: postgres:10.10
    environment:
      POSTGRES_USER: cjworkbench
      POSTGRES_PASSWORD: cjworkbench
      POSTGRES_DB: cjworkbench
      PGDATA: /var/lib/postgresql/data/10.4
    networks: [ 'dev' ]
    volumes:
      - dbdata:/var/lib/postgresql/data

  rabbitmq:
    image: rabbitmq:3.8.11-management
    ports: [ '15672' ] # open management port, for debugging
    networks: [ 'dev' ]
    environment:
      # Use just one CPU
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: '+S 1:1'

  minio:
    image: minio/minio:RELEASE.2020-10-12T21-53-21Z
    networks: [ 'dev' ]
    ports: [ '8001:9000' ]
    environment:
      MINIO_ACCESS_KEY: minio_access
      MINIO_SECRET_KEY: minio_secret
    volumes:
      - minio_data:/data
    entrypoint: ''
    command:
      - sh
      - '-c'
      - |
        PREFIX=dev
        for bucket in user-files static stored-objects external-modules cached-render-results upload; do
            mkdir -p /data/$$PREFIX-$$bucket
        done
        rm -rf /data/.minio.sys
        mkdir -p /data/.minio.sys/buckets/$$PREFIX-static/
        cat > /data/.minio.sys/buckets/$$PREFIX-static/policy.json <<EOT
        {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Sid": "",
                    "Effect": "Allow",
                    "Principal": {"AWS": "*"},
                    "Action": ["s3:GetBucketLocation", "s3:ListBucket"],
                    "Resource": ["arn:aws:s3:::$$PREFIX-static"]
                },
                {
                    "Sid": "",
                    "Effect": "Allow",
                    "Principal": {"AWS": "*"},
                    "Action": ["s3:GetObject"],
                    "Resource": ["arn:aws:s3:::$$PREFIX-static/*"]
                }
            ]
        }
        EOT
        minio server /data

  webpack:
    build:
      context: .
      target: jsbase
    volumes:
      # Migrate 
      - type: bind
        source: ./
        target: /app/
        consistency: cached
      - node_modules:/app/node_modules:rw
      - jest_cache:/tmp/jest_0:rw
    networks: [ 'dev' ]
    command: [ 'node_modules/.bin/webpack', '--mode', 'development', '--watch' ]

  frontend:
    build:
      context: .
      target: pydev
    volumes:
      - type: bind
        source: ./
        target: /app/
        consistency: cached
      - virtualenvs:/root/.local/share/virtualenvs/:rw
    security_opt:
      - seccomp=docker/pyspawner-seccomp-profile.json
    privileged: true
    cap_add: [ SYS_ADMIN ] # for setup-sandboxes.sh to overlay-mount chroots (on k8s we use an init container instead)
    environment: &django-env
      PYTHONUNBUFFERED: '1'
      ASGI_THREADS: '3'
      CJW_DB_HOST: database
      CJW_RABBITMQ_HOST: amqp://guest:guest@rabbitmq/
      CJW_DB_PASSWORD: cjworkbench
      CJW_SECRET_KEY: cjw-secret-key
      TUS_CREATE_UPLOAD_URL: http://tusd/files/
      TUS_EXTERNAL_URL_PREFIX_OVERRIDE: http://localhost:8002/files/
      AWS_ACCESS_KEY_ID: minio_access
      AWS_SECRET_ACCESS_KEY: minio_secret
      AWS_S3_ENDPOINT: http://minio:9000
      S3_BUCKET_NAME_PATTERN: "dev-%s"
    ports: [ '8000:8000', '35729:35729' ]
    networks: [ 'dev' ]
    depends_on: [ 'database', 'rabbitmq', 'minio', 'tusd' ]
    command: [
      'sh',
      '-c',
      # Use httpprocessproxy on port 8000: that's where web browsers will connect.
      # 
      # Even during server restart, port 8000 will listen.
      #
      # Also listen on port 8080 -- _internally_. This lets tusd and stripe
      # connect directly. (They sometimes error when using httpprocessproxy
      # after a restart.) They don't commonly send requests during restart
      # anyway.
      'cjwkernel/setup-sandboxes.sh only-readonly && pipenv run python -m httpprocessproxy 0.0.0.0:8000 0.0.0.0:8080 --exclude "**/*.pyc" "**/tests/**/*" "--pattern" "{intercom_secret,twitter_secret,client_secret}.json" "stripe.env" "cjwkernel/**/*.py" "cjwstate/**/*.py" "cjwstate/**/*.yaml" "server/**/*.py" "templates/**/*.html" "templates/**/*.txt" "server/**/*.yaml" "server/lessons/**/*.html" "server/courses/**/*.html" "cjworkbench/**/*.py" "assets/locale/*/messages.po" --exec python -m uvicorn --host 0.0.0.0 --port 8080 --lifespan on --use-colors --timeout-keep-alive 999999 cjworkbench.asgi:application'
    ]

  renderer:
    # It'd be nice to use YAML anchors to copy these parameters ... but
    # PyCharm's YAML parser seems to die when we use YAML anchors.
    build:
      context: .
      target: pydev
    volumes:
      - type: bind
        source: ./
        target: /app/
        consistency: cached
      - virtualenvs:/root/.local/share/virtualenvs/:rw
    security_opt:
      - seccomp=docker/pyspawner-seccomp-profile.json
    privileged: true
    cap_add:
      - SYS_ADMIN # for setup-sandboxes.sh to overlay-mount chroots (on k8s we use an init container instead)
      - NET_ADMIN # for pyspawner to create new network namespace without access to private network
    environment:
      <<: *django-env
    depends_on: [ 'database', 'rabbitmq', 'minio' ]
    networks: [ 'dev' ]
    command: [
      'sh',
      '-c',
      # Use watchman, not Django autoreload. autoreload crashes when there's a
      # syntax error.
      'cjwkernel/setup-sandboxes.sh all && pipenv run bin/watchman-monitor --exclude "**/*.pyc" "**/tests/**/*" --pattern "cjworkbench/**/*.py" "cjwkernel/**/*.py" "cjwstate/**/*.py" "renderer/**/*.py" --exec bin/renderer-prod'
    ]

  fetcher:
    # It'd be nice to use YAML anchors to copy these parameters ... but
    # PyCharm's YAML parser seems to die when we use YAML anchors.
    build:
      context: .
      target: pydev
    volumes:
      - type: bind
        source: ./
        target: /app/
        consistency: cached
      - virtualenvs:/root/.local/share/virtualenvs/:rw
    security_opt:
      - seccomp=docker/pyspawner-seccomp-profile.json
    privileged: true
    cap_add:
      - SYS_ADMIN # for setup-sandboxes.sh to overlay-mount chroots (on k8s we use an init container instead)
      - NET_ADMIN # for pyspawner to create new network namespace without access to private network
    environment:
      <<: *django-env
    depends_on: [ 'database', 'rabbitmq', 'minio' ]
    networks: [ 'dev' ]
    command: [
      'sh', '-c',
      # Use watchman, not Django autoreload. autoreload crashes when there's a
      # syntax error.
      'cjwkernel/setup-sandboxes.sh all && pipenv run bin/watchman-monitor --exclude "**/*.pyc" "**/tests/**/*" --pattern "{intercom_secret,twitter_secret,client_secret}.json" "cjworkbench/**/*.py" "cjwkernel/**/*.py" "cjwstate/**/*.py" "fetcher/**/*.py" --exec bin/fetcher-prod'
    ]

  cron: &cron
    build:
      context: .
      target: pydev
    volumes:
      - type: bind
        source: ./
        target: /app/
        consistency: cached
      - virtualenvs:/root/.local/share/virtualenvs/:rw
    environment:
      <<: *django-env
    depends_on: [ 'database', 'rabbitmq', 'minio' ]
    networks: [ 'dev' ]
    command: [
      # Use watchman, not Django autoreload. autoreload crashes when there's a
      # syntax error.
      'pipenv', 'run', 'bin/watchman-monitor',
      '--exclude', '**/*.pyc', '**/tests/**/*',
      '--pattern', 'cjworkbench/**/*.py', 'cron/**/*.py', 'cjwstate/models/**/*.*',
      '--exec', 'bin/cron-prod'
    ]

  cron-expired-session-deleter:
    <<: *cron
    depends_on: [ 'database', 'minio' ]
    command: [
      # Use watchman, not Django autoreload. autoreload crashes when there's a
      # syntax error.
      'pipenv', 'run', 'bin/watchman-monitor',
      '--exclude', '**/*.pyc', '**/tests/**/*',
      '--pattern', 'cjworkbench/**/*.py', 'cron/**/*.py', 'cjwstate/models/**/*.*',
      '--exec', 'bin/cron-expired-session-deleter'
    ]

  cron-lesson-autoupdate-disabler:
    <<: *cron
    depends_on: [ 'database' ]
    command: [
      # Use watchman, not Django autoreload. autoreload crashes when there's a
      # syntax error.
      'pipenv', 'run', 'bin/watchman-monitor',
      '--exclude', '**/*.pyc', '**/tests/**/*',
      '--pattern', 'cjworkbench/**/*.py', 'cron/**/*.py', 'cjwstate/models/**/*.*',
      '--exec', 'bin/cron-lesson-autoupdate-disabler'
    ]

  cron-delta-deleter:
    <<: *cron
    depends_on: [ 'database' ]
    command: [
      # Use watchman, not Django autoreload. autoreload crashes when there's a
      # syntax error.
      'pipenv', 'run', 'bin/watchman-monitor',
      '--exclude', '**/*.pyc', '**/tests/**/*',
      '--pattern', 'cjworkbench/**/*.py', 'cron/**/*.py', 'cjwstate/models/**/*.*',
      '--exec', 'bin/cron-delta-deleter'
    ]

  tusd:
    image: tusproject/tusd:v1.4.0
    networks: [ 'dev' ]
    depends_on: [ 'minio' ]
    ports: [ '8002:80' ]
    environment:
      AWS_ACCESS_KEY_ID: minio_access
      AWS_SECRET_ACCESS_KEY: minio_secret
      AWS_REGION: us-east-1
    # No volumes: we don't save data between restarts. (Uploads are temporary.)
    command: [
      '-port=80',
      # Use frontend:8080 -- the Django app, not the proxy. The proxy tries to
      # keep connections alive and clients can sometimes notice.
      '-hooks-http=http://frontend:8080/tusd-hooks',
      '-hooks-enabled-events=pre-finish',
      '-s3-endpoint=http://minio:9000',
      '-s3-bucket=dev-upload',
    ]

  testdatabase:
    image: postgres:10.4
    environment:
      POSTGRES_USER: cjworkbench
      POSTGRES_PASSWORD: cjworkbench
      POSTGRES_DB: cjworkbench
      PGDATA: /var/lib/postgresql/data/10.4
    networks: [ 'test' ]
    volumes:
    - type: tmpfs
      target: /var/lib/postgresql/data
    command: [
      '-c', 'wal_level=minimal',
      '-c', 'max_wal_senders=0',
      '-c', 'fsync=off',
      '-c', 'synchronous_commit=off',
      '-c', 'full_page_writes=off'
    ]

  testrabbitmq:
    image: rabbitmq:3.8.11-management
    networks: [ 'test' ]
    volumes:
      - type: tmpfs
        target: /var/lib/rabbitmq
    environment:
      # Use just one CPU
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: '+S 1:1'

  testminio:
    image: minio/minio:RELEASE.2020-10-12T21-53-21Z
    networks: [ 'test' ]
    volumes:
      - type: tmpfs
        target: /data
    environment:
      MINIO_ACCESS_KEY: minio_access
      MINIO_SECRET_KEY: minio_secret
    entrypoint: ''
    command:
      - sh
      - '-c'
      - |
        PREFIX=unittest
        for bucket in user-files static stored-objects external-modules cached-render-results upload; do
            mkdir -p /data/$$PREFIX-$$bucket
        done
        rm -rf /data/.minio.sys
        mkdir -p /data/.minio.sys/buckets/$$PREFIX-static/
        cat > /data/.minio.sys/buckets/$$PREFIX-static/policy.json <<EOT
        {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Sid": "",
                    "Effect": "Allow",
                    "Principal": {"AWS": "*"},
                    "Action": ["s3:GetBucketLocation", "s3:ListBucket"],
                    "Resource": ["arn:aws:s3:::$$PREFIX-static"]
                },
                {
                    "Sid": "",
                    "Effect": "Allow",
                    "Principal": {"AWS": "*"},
                    "Action": ["s3:GetObject"],
                    "Resource": ["arn:aws:s3:::$$PREFIX-static/*"]
                }
            ]
        }
        EOT
        minio server /data

  testtusd:
    image: tusproject/tusd:v1.4.0
    networks: [ 'test' ]
    depends_on: [ 'testminio' ]
    environment:
      AWS_ACCESS_KEY_ID: minio_access
      AWS_SECRET_ACCESS_KEY: minio_secret
      AWS_REGION: us-east-1
    command: [
      '-port=8080',  # no permission to bind port 80 on google-cloud-build won't bind port 80
      # no hooks in unit tests
      '-s3-endpoint=http://testminio:9000',
      '-s3-bucket=unittest-upload',
    ]

networks:
  dev: {}
  test: {}

volumes:
  dbdata: {}
  minio_data: {}
  virtualenvs: {}
  # Let's not make node_modules a bind mount: Windows bind mounts seem
  # to behave a bit differently from Linux bind mounts. Use a Docker volume
  # instead.
  node_modules: {}
  jest_cache: {}
