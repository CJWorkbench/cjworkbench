# See https://cloud.google.com/cloud-build/docs/build-debug-locally for debug
# instructions.
#
# The copy/paste-able command:
# cloud-build-local --dryrun=false --substitutions COMMIT_SHA=abc123,BRANCH_NAME=branch .
timeout: 2400s
options:
  machineType: N1_HIGHCPU_8
steps:

# Build new Docker images
- name: 'gcr.io/cloud-builders/docker'
  entrypoint: sh
  args:
    - -e
    - -c
    - |
      # --cache-from doesn't work well with multi-stage builds yet: see
      # https://github.com/moby/moby/issues/32612. We don't win if we pull down
      # migrate/renderer/fetcher/cron/frontend and try to build using their
      # caches.
      #
      # One alternative win for build speed: author pull requests for each Python
      # library that uses C, so they push bdist with manylinux. That way our
      # Dockerfile won't need apt-get or gcc calls, saving oodles of time.
      #
      # We can at least pull the latest integration test: our integration tests
      # don't use multi-stage build so they play nice with cache. (That's a great
      # win because installing Firefox deps is particularly slow.)

      # Images for production -- build without cache
      for target in migrate fetcher renderer cron frontend; do
        docker build \
          --target $$target \
          --tag gcr.io/$PROJECT_ID/$$target:$COMMIT_SHA \
          --tag gcr.io/$PROJECT_ID/$$target:$BRANCH_NAME \
          --tag gcr.io/$PROJECT_ID/$$target:latest \
          .
      done

      # Build integration-test images -- first pulling from cache if it can be used
      docker pull gcr.io/$PROJECT_ID/integration-test:latest || true
      docker build --pull \
        --file Dockerfile.integrationtest \
        --target cloudbuild \
        --tag gcr.io/$PROJECT_ID/integration-test:$COMMIT_SHA \
        --tag gcr.io/$PROJECT_ID/integration-test:latest \
        .
      docker build \
        --tag gcr.io/$PROJECT_ID/git-server:$COMMIT_SHA \
        ./integrationtests/git-server

# Unit-test
- name: 'docker/compose:1.24.1'
  args: [ '-f', 'server/tests/docker-compose.yml',
          'run',
          'unittest'
        ]
  env:
    - 'PROJECT_ID=$PROJECT_ID'
    - 'COMMIT_SHA=$COMMIT_SHA'
# Integration-test: addminiouser, migrate, then run the integration-test image
- name: 'docker/compose:1.24.1'
  args: [ '-f', 'integrationtests/docker-compose.yml',
          '-f', 'integrationtests/docker-compose.cloudbuild-override.yml',
          'run',
          'addminiouser'
        ]
  env:
    - 'PROJECT_ID=$PROJECT_ID'
    - 'COMMIT_SHA=$COMMIT_SHA'
- name: 'docker/compose:1.24.1'
  args: [ '-f', 'integrationtests/docker-compose.yml',
          '-f', 'integrationtests/docker-compose.cloudbuild-override.yml',
          'run',
          'migrate'
        ]
  env:
    - 'PROJECT_ID=$PROJECT_ID'
    - 'COMMIT_SHA=$COMMIT_SHA'
- name: 'docker/compose:1.24.1'
  args: [ '-f', 'integrationtests/docker-compose.yml',
          '-f', 'integrationtests/docker-compose.cloudbuild-override.yml',
          'run',
          'integration-test'
        ]
  env:
    - 'PROJECT_ID=$PROJECT_ID'
    - 'COMMIT_SHA=$COMMIT_SHA'

# Push images (so we can deploy)
- name: 'gcr.io/cloud-builders/docker'
  entrypoint: sh
  args:
    - -e
    - -c
    - |
      for target in migrate fetcher renderer cron frontend; do
        docker push gcr.io/$PROJECT_ID/$$target:$COMMIT_SHA
        # Push a couple of aliases. We don't strictly need these, but they
        # shouldn't cost much time or disk because the layers are already up.
        docker push gcr.io/$PROJECT_ID/$$target:$BRANCH_NAME
        docker push gcr.io/$PROJECT_ID/$$target:latest
      done

# Deploy! (to staging server)
- name: 'gcr.io/cloud-builders/kubectl'
  entrypoint: bash
  args:
    - -e
    - -c
    - |
      # We overrode entrypoint; so we copy/paste its original stuff from
      # https://github.com/GoogleCloudPlatform/cloud-builders/blob/master/kubectl/kubectl.bash
      # BEGIN COPY/PASTE (doubling up '$$' for cloudbuild escape syntax)
      # If there is no current context, get one.
      if [[ $$(kubectl config current-context 2> /dev/null) == "" ]]; then
        cluster=$$(gcloud config get-value container/cluster 2> /dev/null)
        zone=$$(gcloud config get-value compute/zone 2> /dev/null)
        project=$$(gcloud config get-value core/project 2> /dev/null)

        function var_usage() {
          cat <<EOF
      No cluster is set. To set the cluster (and the zone where it is found), set the environment variables
        CLOUDSDK_COMPUTE_ZONE=<cluster zone>
        CLOUDSDK_CONTAINER_CLUSTER=<cluster name>
      EOF
          exit 1
        }

        [[ -z "$$cluster" ]] && var_usage
        [[ -z "$$zone" ]] && var_usage

        echo "Running: gcloud container clusters get-credentials --project=\"$$project\" --zone=\"$$zone\" \"$$cluster\""  >&2
        gcloud container clusters get-credentials --project="$$project" --zone="$$zone" "$$cluster" || exit
      fi
      # END COPY/PASTE
      # ... now we can get on with our actual script

      if [ "$BRANCH_NAME" = "master" ]; then
        deploy/advanced-deploy staging "$COMMIT_SHA"
        echo 'Deployed to staging. Run `deploy/update-production-to-staging` to deploy to production.' >&2
      else
        echo 'Skipped deploy to staging: branch "$BRANCH_NAME" is not master' >&2
      fi
  env:
    - 'CLOUDSDK_COMPUTE_ZONE=us-central1-b'
    - 'CLOUDSDK_CONTAINER_CLUSTER=workbench'

# Display images in Google Cloud Build status pages. (We pushed them
# manually, so this doesn't actually do anything new.)
images:
- 'gcr.io/$PROJECT_ID/migrate:$COMMIT_SHA'
- 'gcr.io/$PROJECT_ID/fetcher:$COMMIT_SHA'
- 'gcr.io/$PROJECT_ID/renderer:$COMMIT_SHA'
- 'gcr.io/$PROJECT_ID/cron:$COMMIT_SHA'
- 'gcr.io/$PROJECT_ID/frontend:$COMMIT_SHA'
- 'gcr.io/$PROJECT_ID/integration-test:latest' # cache this layer -- we can pull it to speed up future builds
